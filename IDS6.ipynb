{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory exercise 6\n",
    "\n",
    "The notebook contains exercises connected to auditory exercise 7. For any questions feel free to contact assistant: eda.jovicic@fer.hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main task of this notebook is to make predictions using supported learning with the Scikit Learn library. The goal is to predict the grade in Math considering other features of the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the cleaned dataset from the first exercise. If you haven't saved the dataset, rerun the exercise and save the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>EthnicGroup</th>\n",
       "      <th>ParentEduc</th>\n",
       "      <th>LunchType</th>\n",
       "      <th>TestPrep</th>\n",
       "      <th>ParentMaritalStatus</th>\n",
       "      <th>PracticeSport</th>\n",
       "      <th>IsFirstChild</th>\n",
       "      <th>NrSiblings</th>\n",
       "      <th>TransportMeans</th>\n",
       "      <th>WklyStudyHours</th>\n",
       "      <th>MathScore</th>\n",
       "      <th>ReadingScore</th>\n",
       "      <th>WritingScore</th>\n",
       "      <th>Gender_female</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>LunchType_free/reduced</th>\n",
       "      <th>LunchType_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29113</th>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29114</th>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>standard</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29116</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>standard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  EthnicGroup  ParentEduc     LunchType  TestPrep  \\\n",
       "0      female            2           1      standard         1   \n",
       "1      female            2           5      standard         1   \n",
       "2      female            1           3      standard         1   \n",
       "3        male            0           0  free/reduced         1   \n",
       "4        male            2           5      standard         1   \n",
       "...       ...          ...         ...           ...       ...   \n",
       "29112  female            3           2      standard         1   \n",
       "29113    male            4           2      standard         1   \n",
       "29114  female            2           2  free/reduced         0   \n",
       "29115  female            3           0      standard         0   \n",
       "29116    male            1           5      standard         1   \n",
       "\n",
       "       ParentMaritalStatus  PracticeSport  IsFirstChild  NrSiblings  \\\n",
       "0                        1              1             1         3.0   \n",
       "1                        1              2             1         0.0   \n",
       "2                        2              2             1         4.0   \n",
       "3                        1              0             0         1.0   \n",
       "4                        1              2             1         0.0   \n",
       "...                    ...            ...           ...         ...   \n",
       "29112                    2              2             0         2.0   \n",
       "29113                    2              1             0         1.0   \n",
       "29114                    1              2             0         1.0   \n",
       "29115                    1              1             0         3.0   \n",
       "29116                    1              0             0         1.0   \n",
       "\n",
       "       TransportMeans  WklyStudyHours  MathScore  ReadingScore  WritingScore  \\\n",
       "0                   1               1         71            71            74   \n",
       "1                   2               0         69            90            88   \n",
       "2                   1               1         87            93            91   \n",
       "3                   2               0         45            56            42   \n",
       "4                   1               0         76            78            75   \n",
       "...               ...             ...        ...           ...           ...   \n",
       "29112               1               0         59            61            65   \n",
       "29113               0               0         58            53            51   \n",
       "29114               0               0         61            70            67   \n",
       "29115               1               0         82            90            93   \n",
       "29116               1               0         64            60            58   \n",
       "\n",
       "       Gender_female  Gender_male  LunchType_free/reduced  LunchType_standard  \n",
       "0                1.0          0.0                     0.0                 1.0  \n",
       "1                1.0          0.0                     0.0                 1.0  \n",
       "2                1.0          0.0                     0.0                 1.0  \n",
       "3                0.0          1.0                     1.0                 0.0  \n",
       "4                0.0          1.0                     0.0                 1.0  \n",
       "...              ...          ...                     ...                 ...  \n",
       "29112            1.0          0.0                     0.0                 1.0  \n",
       "29113            0.0          1.0                     0.0                 1.0  \n",
       "29114            1.0          0.0                     1.0                 0.0  \n",
       "29115            1.0          0.0                     0.0                 1.0  \n",
       "29116            0.0          1.0                     0.0                 1.0  \n",
       "\n",
       "[29117 rows x 18 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Učitavanje dataseta\n",
    "import pandas as pd\n",
    "students = pd.read_csv(\"studentslab.csv\")\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transform the MathScore feature into grades (1-5) using the following scoring system:\n",
    "\n",
    "|   MathScore |  Grade  |\n",
    "| ----------- | ------- |\n",
    "|  88 - 100   |    5    |\n",
    "|  75 - 87    |    4    |\n",
    "|  63 - 74    |    3    |\n",
    "|  50 - 62    |    2    |\n",
    "|   0 - 49    |    1    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MathScore Grade\n",
      "0             71     3\n",
      "1             69     3\n",
      "2             87     5\n",
      "3             45     1\n",
      "4             76     4\n",
      "...          ...   ...\n",
      "29112         59     2\n",
      "29113         58     2\n",
      "29114         61     2\n",
      "29115         82     4\n",
      "29116         64     3\n",
      "\n",
      "[29117 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Definiranje\n",
    "bins = [-1, 49, 62, 74, 87, 100]\n",
    "grades = [1, 2, 3, 4, 5]\n",
    "\n",
    "#Stupac 'Grade'\n",
    "students['Grade'] = pd.cut(students['MathScore'], bins=bins, labels=grades, right=False)\n",
    "\n",
    "print(students[['MathScore', 'Grade']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Divide the dataset into features (X) and predictions (y). For features we will use all the columns except MathScore, ReadingScore and WritingScore. For predictions we will use the MathScore column. Split the dataset into training and testing sets. The split should be done in a  70-30% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EthnicGroup</th>\n",
       "      <th>ParentEduc</th>\n",
       "      <th>TestPrep</th>\n",
       "      <th>ParentMaritalStatus</th>\n",
       "      <th>PracticeSport</th>\n",
       "      <th>IsFirstChild</th>\n",
       "      <th>NrSiblings</th>\n",
       "      <th>TransportMeans</th>\n",
       "      <th>WklyStudyHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "      <td>29117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.172957</td>\n",
       "      <td>3.080881</td>\n",
       "      <td>0.675276</td>\n",
       "      <td>1.109077</td>\n",
       "      <td>1.372635</td>\n",
       "      <td>0.642030</td>\n",
       "      <td>2.147714</td>\n",
       "      <td>0.730501</td>\n",
       "      <td>0.607995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.105460</td>\n",
       "      <td>2.190324</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.709069</td>\n",
       "      <td>0.479411</td>\n",
       "      <td>1.428635</td>\n",
       "      <td>0.633428</td>\n",
       "      <td>0.760503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EthnicGroup    ParentEduc      TestPrep  ParentMaritalStatus  \\\n",
       "count  29117.000000  29117.000000  29117.000000         29117.000000   \n",
       "mean       2.172957      3.080881      0.675276             1.109077   \n",
       "std        1.105460      2.190324      0.468280             0.676667   \n",
       "min        0.000000      0.000000      0.000000             0.000000   \n",
       "25%        1.000000      1.000000      0.000000             1.000000   \n",
       "50%        2.000000      3.000000      1.000000             1.000000   \n",
       "75%        3.000000      5.000000      1.000000             2.000000   \n",
       "max        4.000000      6.000000      1.000000             3.000000   \n",
       "\n",
       "       PracticeSport  IsFirstChild    NrSiblings  TransportMeans  \\\n",
       "count   29117.000000  29117.000000  29117.000000    29117.000000   \n",
       "mean        1.372635      0.642030      2.147714        0.730501   \n",
       "std         0.709069      0.479411      1.428635        0.633428   \n",
       "min         0.000000      0.000000      0.000000        0.000000   \n",
       "25%         1.000000      0.000000      1.000000        0.000000   \n",
       "50%         2.000000      1.000000      2.000000        1.000000   \n",
       "75%         2.000000      1.000000      3.000000        1.000000   \n",
       "max         2.000000      1.000000     26.000000        2.000000   \n",
       "\n",
       "       WklyStudyHours  \n",
       "count    29117.000000  \n",
       "mean         0.607995  \n",
       "std          0.760503  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max          2.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X (sve osim MathScore, ReadingScore, WritingScore) and y (MathScore)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "col = ['EthnicGroup', 'ParentEduc', 'TestPrep', 'ParentMaritalStatus', 'PracticeSport', 'IsFirstChild', 'NrSiblings', 'TransportMeans', 'WklyStudyHours']\n",
    "X = students[col]\n",
    "y = students.MathScore\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20381, 9)\n",
      "X_test shape: (8736, 9)\n",
      "y_train shape: (20381,)\n",
      "y_test shape: (8736,)\n"
     ]
    }
   ],
   "source": [
    "#Razdvajanje dataseta na train i test (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a Random Forest model, with max_depth=5 and n_estimators=20. Train the model using training set, and then test it on testing set. Display the confusion matrix. Show precision, recall and F1 score for all grades. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  1]\n",
      " [ 0  0  0 ...  0  0  2]\n",
      " [ 0  0  0 ...  0  0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           7       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00        10\n",
      "          27       0.00      0.00      0.00         8\n",
      "          28       0.00      0.00      0.00        16\n",
      "          29       0.00      0.00      0.00        12\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        22\n",
      "          32       0.00      0.00      0.00        25\n",
      "          33       0.00      0.00      0.00        28\n",
      "          34       0.00      0.00      0.00        16\n",
      "          35       0.00      0.00      0.00        29\n",
      "          36       0.00      0.00      0.00        33\n",
      "          37       0.00      0.00      0.00        35\n",
      "          38       0.00      0.00      0.00        42\n",
      "          39       0.00      0.00      0.00        53\n",
      "          40       0.00      0.00      0.00        51\n",
      "          41       0.00      0.00      0.00        57\n",
      "          42       0.00      0.00      0.00        61\n",
      "          43       0.00      0.00      0.00        58\n",
      "          44       0.00      0.00      0.00        85\n",
      "          45       0.00      0.00      0.00        97\n",
      "          46       0.00      0.00      0.00        84\n",
      "          47       0.11      0.01      0.02        95\n",
      "          48       0.00      0.00      0.00       113\n",
      "          49       0.00      0.00      0.00        98\n",
      "          50       0.00      0.00      0.00       124\n",
      "          51       0.00      0.00      0.00       136\n",
      "          52       0.00      0.00      0.00       137\n",
      "          53       0.00      0.00      0.00       159\n",
      "          54       0.00      0.00      0.00       141\n",
      "          55       0.00      0.00      0.00       148\n",
      "          56       0.00      0.00      0.00       175\n",
      "          57       0.00      0.00      0.00       187\n",
      "          58       0.02      0.01      0.01       187\n",
      "          59       0.00      0.00      0.00       201\n",
      "          60       0.04      0.04      0.04       196\n",
      "          61       0.05      0.03      0.03       195\n",
      "          62       0.02      0.09      0.04       214\n",
      "          63       0.01      0.02      0.01       214\n",
      "          64       0.03      0.45      0.06       250\n",
      "          65       0.04      0.03      0.03       217\n",
      "          66       0.03      0.02      0.02       211\n",
      "          67       0.03      0.17      0.05       235\n",
      "          68       0.00      0.00      0.00       153\n",
      "          69       0.02      0.00      0.01       208\n",
      "          70       0.04      0.04      0.04       209\n",
      "          71       0.03      0.06      0.04       237\n",
      "          72       0.05      0.00      0.01       211\n",
      "          73       0.00      0.00      0.00       217\n",
      "          74       0.16      0.02      0.03       185\n",
      "          75       0.01      0.01      0.01       207\n",
      "          76       0.04      0.02      0.03       193\n",
      "          77       0.04      0.01      0.02       190\n",
      "          78       0.00      0.00      0.00       170\n",
      "          79       0.02      0.01      0.01       187\n",
      "          80       0.03      0.05      0.03       172\n",
      "          81       0.00      0.00      0.00       148\n",
      "          82       0.03      0.01      0.01       138\n",
      "          83       0.02      0.01      0.01       131\n",
      "          84       0.00      0.00      0.00       130\n",
      "          85       0.07      0.01      0.01       134\n",
      "          86       0.00      0.00      0.00       116\n",
      "          87       0.00      0.00      0.00       111\n",
      "          88       0.00      0.00      0.00        88\n",
      "          89       0.00      0.00      0.00        88\n",
      "          90       0.00      0.00      0.00        76\n",
      "          91       0.00      0.00      0.00        83\n",
      "          92       0.00      0.00      0.00        67\n",
      "          93       0.00      0.00      0.00        57\n",
      "          94       0.00      0.00      0.00        59\n",
      "          95       0.00      0.00      0.00        47\n",
      "          96       0.00      0.00      0.00        47\n",
      "          97       0.00      0.00      0.00        47\n",
      "          98       0.00      0.00      0.00        18\n",
      "          99       0.00      0.00      0.00        31\n",
      "         100       0.12      0.17      0.15        80\n",
      "\n",
      "    accuracy                           0.03      8736\n",
      "   macro avg       0.01      0.01      0.01      8736\n",
      "weighted avg       0.02      0.03      0.01      8736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imlau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\imlau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\imlau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#Isključivanje nenumeričke stupce i ciljnu varijablu 'MathScore'\n",
    "#X = students.drop(columns=['MathScore', 'ReadingScore', 'WritingScore', 'TestPrep', 'ParentMaritalStatus'])\n",
    "#y = students['MathScore']\n",
    "\n",
    "#categorical_cols = ['TestPrep', 'ParentMaritalStatus']  # Update with your categorical columns\n",
    "#X_categorical = pd.get_dummies(students[categorical_cols])\n",
    "\n",
    "#X = pd.concat([X, X_categorical], axis=1)\n",
    "\n",
    "#rows_with_nan = y[y.isnull()].index\n",
    "\n",
    "#X = X.drop(rows_with_nan)\n",
    "#y = y.drop(rows_with_nan)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0, n_estimators=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred)) #Ni ovo ne ispada dobro\n",
    "\n",
    "#Razdvajanje dataseta na train i test (70% train, 30% test)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Stvaranje i treniranje modela Random Forest\n",
    "#rf_model = RandomForestClassifier(n_estimators=20, max_depth=5, random_state=42)\n",
    "#rf_model.fit(X_train, y_train)\n",
    "\n",
    "#Predikcije\n",
    "#y_pred = rf_model.predict(X_test)\n",
    "\n",
    "#conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print(\"Confusion Matrix:\")\n",
    "#print(conf_matrix)\n",
    "\n",
    "#Izračunavanje preciznosti, opoziva i F1 rezultata za sve ocjene pomoću classification_report\n",
    "#grades = sorted(pd.unique(y_test))\n",
    "#report = classification_report(y_test, y_pred, labels=grades)\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The accuracy of our model is not the best. The reason could be having too many possible classes (grades). Let's transform the data again, but this time, instead of predicting grades, we want to predict whether the student will pass (grades 2, 3, 4 and 5) or fail (grade 1) math. After transforming the MathScore accordingly (0 - failed, 1 - passed), repeat task 4 and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        NaN\n",
       "2        NaN\n",
       "3        NaN\n",
       "4        NaN\n",
       "        ... \n",
       "29112    NaN\n",
       "29113    NaN\n",
       "29114    NaN\n",
       "29115    NaN\n",
       "29116    NaN\n",
       "Name: MathScore, Length: 29117, dtype: category\n",
       "Categories (2, int64): [0 < 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#Pretvaranje stupca 'MathScore' u prolaz (1) ili pad (0)\n",
    "#students['MathOutcome'] = students['MathScore'].apply(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "#Isključivanje nenumeričkih stupaca i ciljne varijable 'MathScore', 'ReadingScore', 'WritingScore'\n",
    "#X = students.drop(columns=['MathScore', 'ReadingScore', 'WritingScore', 'MathOutcome', 'TestPrep', 'ParentMaritalStatus'])\n",
    "#y = students['MathOutcome']\n",
    "\n",
    "#categorical_cols = ['TestPrep', 'ParentMaritalStatus']  # Update with your categorical columns\n",
    "#X_categorical = pd.get_dummies(students[categorical_cols])\n",
    "\n",
    "#X = pd.concat([X, X_categorical], axis=1)\n",
    "\n",
    "#Razdvajanje dataseta na train i test (70% train, 30% test)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "students[\"MathScore\"]=pd.cut(x=students[\"MathScore\"], bins=[0, 1, 5], labels=[0,1])\n",
    "students[\"MathScore\"] #Ni ovo ne ispada dobro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#Random Forest model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test, y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1173\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1173\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1174\u001b[0m         y,\n\u001b[0;32m   1175\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1176\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1177\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1178\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1179\u001b[0m         input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1180\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1181\u001b[0m     )\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1183\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "#rf_model = RandomForestClassifier(n_estimators=20, max_depth=5, random_state=42)\n",
    "#rf_model.fit(X_train, y_train)\n",
    "\n",
    "#Predikcije\n",
    "#y_pred = rf_model.predict(X_test)\n",
    "\n",
    "#conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#print(\"Confusion Matrix:\")\n",
    "#print(conf_matrix)\n",
    "\n",
    "#report = classification_report(y_test, y_pred)\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(report)\n",
    "\n",
    "y = students.MathScore\n",
    "#splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "#Random Forest model\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0, n_estimators=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred)) #Ni ovo ne ispada dobro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compare the results. Did our model work better in the first case or the second? Explain why and suggest a way to improve it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Binary classification for pass/fail prediction often holds an advantage over a random forest model predicting multiple grades due to its simplicity, interpretability, and reduced complexity. By categorizing student performance into two distinct classes - passing or failing, binary classification simplifies the prediction task. This simplicity not only eases model interpretation but also reduces the complexity of the problem by dealing with fewer classes, making it potentially easier for the model to learn distinguishing features. The pass/fail classification can sometimes offer a more balanced dataset compared to predicting multiple grade levels. Balanced classes allow models to perform better, reducing biases towards dominant classes and potentially leading to higher accuracy. Additionally, the binary approach is more robust against variations in grading criteria or subjective evaluation, as it focuses on a broader, more categorical outcome rather than fine-grained distinctions among multiple grades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
